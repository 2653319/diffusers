{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0ea2f8-25c0-4be7-adbf-c5c47cfc0f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\diffusers_5\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "A matching Triton is not available, some optimizations will not be enabled\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda\\envs\\diffusers_5\\lib\\site-packages\\xformers\\__init__.py\", line 57, in _is_triton_available\n",
      "    import triton  # noqa\n",
      "ModuleNotFoundError: No module named 'triton'\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "import requests\n",
    "import torch\n",
    "from diffusers import StableDiffusionInstructPix2PixPipeline, EulerAncestralDiscreteScheduler\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "from diffusers import DiffusionPipeline\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "import lpips\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from math import sqrt\n",
    "import inspect, diffusers\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, StableDiffusionInstructPix2PixPipeline, UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeed28fb-efd5-4dc2-8534-c22751d46914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create img\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7290f053-5942-4d54-9d8f-1b65c8f97913",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=\"E:/RainTest/Rain100H_512/input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc7219ea-7997-471d-9103-525a4967e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_instruct_pix2pix.StableDiffusionInstructPix2PixPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "model_id = \"instruct-pix2pix-model_base_23299\"\n",
    "pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(model_id, torch_dtype=torch.bfloat16 ,safety_checker=None).to(\"cuda\")\n",
    "generator = torch.Generator(\"cuda\").manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "315e9302-6d13-4398-a4d2-66e319d86a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"derain the image\"\n",
    "num_inference_steps = 60\n",
    "image_guidance_scale = 1.03\n",
    "guidance_scale = 2\n",
    "uncond_scale=0.01\n",
    "mode = \"1\"\n",
    "output_dir = \"E:/RainTest/output/Rain100H_mode1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "10e3534a-9890-49e0-b126-3d49ae4b1197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.91it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.66it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.74it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 13.02it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 13.02it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 13.01it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 13.00it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 13.00it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.99it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.98it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.97it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.97it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.77it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.97it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.94it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.55it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.80it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.87it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.75it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.90it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.86it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.85it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.95it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.90it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.91it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.89it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.90it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.96it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.87it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.90it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.95it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.86it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.49it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.59it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.53it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.66it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.54it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.74it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.95it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.96it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.59it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.39it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.56it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.76it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.76it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.83it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.79it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.86it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.88it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.66it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.69it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.71it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.70it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.79it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.90it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.88it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.81it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.93it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.78it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.86it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.81it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.72it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.86it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.88it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.63it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.76it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.82it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.56it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.52it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.97it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.88it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.87it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.48it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.51it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.67it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.63it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.78it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.84it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.79it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.70it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.71it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.73it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.83it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.92it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.89it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.87it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.67it/s]\n",
      "100%|██████████| 60/60 [00:04<00:00, 12.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for example in dataset['train']:\n",
    "    image = example[\"image\"] \n",
    "    image = image.convert(\"RGB\") \n",
    "    \n",
    "    original_filename = os.path.basename(example[\"image\"].filename)\n",
    "\n",
    "    image_path = os.path.join(output_dir, original_filename)  \n",
    "\n",
    "    edited_image = pipe(prompt,\n",
    "        image=image,\n",
    "        mode=mode,\n",
    "        uncond_scale=uncond_scale,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        image_guidance_scale=image_guidance_scale,\n",
    "        guidance_scale=guidance_scale,\n",
    "        generator=generator,\n",
    "    ).images[0]\n",
    "    edited_image.save(image_path, \"PNG\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6b4d3e81-3869-4cf5-9fb2-b71ff1698d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscore\\n'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "score\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aba6de4-8e3c-489e-a69c-711a5ca1422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ssim(img1, img2):\n",
    "    \"\"\"\n",
    "    range: [0, 1]\n",
    "    return : ssim\n",
    "    \"\"\"\n",
    "    return structural_similarity(img1, img2, data_range=255, channel_axis=-1)\n",
    "    \n",
    "def compute_lpips(img1, img2):\n",
    "    \"\"\"\n",
    "    img1, img2: NumPy array，shape = (H, W, 3)，\n",
    "    range: [0, 255].\n",
    "    return:lpips\n",
    "    \"\"\"\n",
    "    #to tensor, shape:(N, C, H, W)\n",
    "    t1 = torch.from_numpy(img1).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    t2 = torch.from_numpy(img2).permute(2, 0, 1).unsqueeze(0).float()\n",
    "    # [-1, 1]\n",
    "    t1 = t1 / 255.0 * 2 - 1\n",
    "    t2 = t2 / 255.0 * 2 - 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dist = lpips_fn(t1, t2)\n",
    "    return dist.item()\n",
    "\n",
    "def compute_psnr(img1, img2):\n",
    "    \"\"\"\n",
    "    img1, img2: NumPy array，shape = (H, W, 3)\n",
    "    range: [0, 255]\n",
    "    return: psnr\n",
    "    \"\"\"\n",
    "    return peak_signal_noise_ratio(img1, img2, data_range=255)\n",
    "\n",
    "def evaluate_metrics(dataset_input, dataset_gt):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    lpips_values = []\n",
    "\n",
    "    n_data = len(dataset_input[\"train\"])\n",
    "    print(\"All:\",n_data)\n",
    "\n",
    "    for idx in range(n_data):\n",
    "\n",
    "        input_image = dataset_input[\"train\"][idx][\"image\"]  \n",
    "        gt_image = dataset_gt[\"train\"][idx][\"image\"]       \n",
    "\n",
    "        input_np = np.array(input_image)\n",
    "        gt_np = np.array(gt_image)\n",
    "\n",
    "        #PSNR\n",
    "        psnr_val = compute_psnr(gt_np, input_np)\n",
    "        psnr_values.append(psnr_val)\n",
    "\n",
    "        #SSIM\n",
    "        ssim_val = compute_ssim(gt_np, input_np)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "        #LPIPS\n",
    "        lpips_val = compute_lpips(gt_np, input_np)\n",
    "        lpips_values.append(lpips_val)\n",
    "\n",
    "\n",
    "    #mean\n",
    "    mean_psnr = np.mean(psnr_values)\n",
    "    mean_ssim = np.mean(ssim_values)\n",
    "    mean_lpips = np.mean(lpips_values)\n",
    "\n",
    "    return mean_psnr, mean_ssim, mean_lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f67495d9-d5dc-4c1f-8bab-5427820216f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 100/100 [00:00<?, ?files/s]\n",
      "Generating train split: 100 examples [00:00, 28501.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_gt = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=\"E:/RainTest/Rain100H_512/target\"\n",
    ")\n",
    "\n",
    "dataset_edited = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=\"E:/RainTest/output/Rain100H_mode1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50cd236-7015-4130-b5bc-6df9488e554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(ds):\n",
    "    return [os.path.basename(ex[\"image\"].filename) for ex in ds[\"train\"]]\n",
    "\n",
    "names_before = get_filenames(dataset_edited)\n",
    "names_after  = get_filenames(dataset_gt)\n",
    "if names_before == names_after:\n",
    "    print(\"一致\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b728e-635e-412f-bcf8-ec0e52d3ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpips_fn = lpips.LPIPS(net='alex')\n",
    "\n",
    "mean_psnr_base, mean_ssim_base, mean_lpips_base = evaluate_metrics(dataset_edited, dataset_gt)\n",
    "print(f\"base平均 PSNR:  {mean_psnr_base}\")\n",
    "print(f\"base平均 SSIM:  {mean_ssim_base:}\")\n",
    "print(f\"base平均 LPIPS: {mean_lpips_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5a7d8-d165-47e9-a9cb-496dad37c998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dba2bb-bab6-4f3c-a8da-66491791fee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
